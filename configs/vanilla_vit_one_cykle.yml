---
model: vit
dataset: imagenet1k
path_dataset: False
optimizer: adam
# 'exclude the parameters of the LayerNorm for weight decay. 
#Or you can just turn off weight decay, it usually makes minor difference
#'https://github.com/lucidrains/vit-pytorch/issues/55
wd: 0.00
ignore_index: -100
label_smoothing: 0.0001
#in  https://github.com/google-research/vision_transformer/issues/89 they propose batchsize of 4096 ==(256*16) and warmup for 10000 steps. (1281167 images / 4096 == 312 steps per epoch  --> 10000 steps == 32 epochs)
epochs: 32

lr: 0.001
learning_rate_schedule:
 name: fit_one_cykle
batchsize: 256
accumulate_grad_batches: 16
#gradient norml clip should be 1. acoridng to 'how to train your vit'
gradient_clip_val: 1.0
save_interval: 100
save_dir: "logsWarmupStartfromzero/"
val_check_interval: 1
log_every_n_steps: 550
accelerator: auto
state_dict_path_load: False
resume_training: False
experment_name: "vit warmup on imagenet1k"
loss: cross_entropy
#print out when training

#  | Name           | Type               | Params
#------------------------------------------------------
#0 | model          | Vit                | 88.2 M
#1 | val_accuracy   | MulticlassAccuracy | 0
#2 | test_accuracy  | MulticlassAccuracy | 0
#3 | train_accuracy | MulticlassAccuracy | 0
#4 | loss           | CrossEntropyLoss   | 0
#------------------------------------------------------
#88.2 M    Trainable params
#0         Non-trainable params
#88.2 M    Total params
#352.897   Total estimated model params size (MB)
#Epoch 0:   2%|â–Š                                                   | 80/5201 [00:54<58:11,  1.47it/s, loss=6.91, v_num=5, train_loss=6.910, train_acc=0.00391]
